"""
SBIè¨¼åˆ¸ æ¥­ç¨®åˆ¥é¨°è½ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°è‡ªå‹•å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

SBIè¨¼åˆ¸ã®æ¥­ç¨®åˆ¥æ ªä¾¡å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå‰æ—¥æ¯”ï¼‰ã‚’å–å¾—ã—ã€LINEé€šçŸ¥ã—ã¾ã™ã€‚
GitHub Actionsã‹ã‚‰å®šæœŸå®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚
"""

import datetime
import json
import logging
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from zoneinfo import ZoneInfo

import requests
from bs4 import BeautifulSoup

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

from config import (
    RETRY_COUNT,
    RETRY_DELAYS,
    REQUEST_TIMEOUT,
    SECTOR_DATA_DIR,
    SECTOR_TIME_SLOTS,
    SECTOR_URL,
    USER_AGENT,
)

# check_workday.py ã® is_trading_day ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from check_workday import is_trading_day
    CHECK_WORKDAY_FALLBACK = False
except ImportError:
    CHECK_WORKDAY_FALLBACK = True
    import jpholiday

    def is_trading_day(target_date: datetime.date) -> bool:
        """ç°¡æ˜“ç‰ˆ: åœŸæ—¥ç¥ã‚’é™¤å¤–"""
        if target_date.weekday() >= 5:  # åœŸæ—¥
            return False
        if jpholiday.is_holiday(target_date):  # ç¥æ—¥
            return False
        return True

# notify_line.py ã® send_line_message ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from notify_line import send_line_message as send_line_notify
    LINE_NOTIFY_AVAILABLE = True
except ImportError:
    LINE_NOTIFY_AVAILABLE = False

    def send_line_notify(message: str) -> bool:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ã‚°å‡ºåŠ›ã®ã¿"""
        logging.info("[LINEé€šçŸ¥] %s", message)
        return True

# ===========================
# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
# ===========================

logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# ===========================
# å®šæ•°
# ===========================

JST = ZoneInfo("Asia/Tokyo")
DATA_ROOT = PROJECT_ROOT / SECTOR_DATA_DIR
DATETIME_FORMAT = "%Y%m%d_%H%M"

# ===========================
# ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—
# ===========================


def scrape_sector_ranking(url: str) -> List[Dict[str, str]]:
    """
    SBIè¨¼åˆ¸ã®æ¥­ç¨®åˆ¥é¨°è½ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹ã€‚

    Args:
        url: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡URL

    Returns:
        List[Dict]: æ¥­ç¨®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            [{"rank": "1", "sector": "...", "change_percent": "+1.23%", ...}, ...]

    Raises:
        requests.exceptions.RequestException: HTTPé€šä¿¡ã‚¨ãƒ©ãƒ¼
        AttributeError: HTMLæ§‹é€ ã®è§£æå¤±æ•—
    """
    headers = {"User-Agent": USER_AGENT}

    for attempt in range(1, RETRY_COUNT + 1):
        try:
            logger.info("ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ã‚’è©¦è¡Œã—ã¾ã™ï¼ˆ%d/%dï¼‰", attempt, RETRY_COUNT)
            response = requests.get(
                url, headers=headers, timeout=REQUEST_TIMEOUT, allow_redirects=True
            )
            response.raise_for_status()
            logger.info("HTTP %d: ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ", response.status_code)
            break
        except requests.exceptions.RequestException as exc:
            logger.warning("HTTPé€šä¿¡ã‚¨ãƒ©ãƒ¼ï¼ˆè©¦è¡Œ %d/%dï¼‰: %s", attempt, RETRY_COUNT, exc)
            if attempt < RETRY_COUNT:
                delay = RETRY_DELAYS[min(attempt - 1, len(RETRY_DELAYS) - 1)]
                logger.info("%dç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...", delay)
                import time
                time.sleep(delay)
            else:
                logger.error("æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚å–å¾—ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                raise

    soup = BeautifulSoup(response.content, "lxml")

    # SBIè¨¼åˆ¸ã®æ¥­ç¨®åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
    # å®Ÿéš›ã®HTMLæ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦
    table = soup.find("table", class_="md-l-table-01")
    if not table:
        table = soup.find("table")

    if not table:
        raise AttributeError("æ¥­ç¨®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚HTMLæ§‹é€ ãŒå¤‰æ›´ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    rankings = []
    rows = table.find_all("tr")

    for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
        cols = row.find_all(["td", "th"])
        if len(cols) < 3:
            continue

        try:
            rank = cols[0].get_text(strip=True)
            sector = cols[1].get_text(strip=True)
            change_percent = cols[2].get_text(strip=True)

            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: è¿½åŠ ã®åˆ—ãŒã‚ã‚Œã°å–å¾—
            value = cols[3].get_text(strip=True) if len(cols) > 3 else ""
            change = cols[4].get_text(strip=True) if len(cols) > 4 else ""

            rankings.append({
                "rank": rank,
                "sector": sector,
                "change_percent": change_percent,
                "value": value,
                "change": change,
            })

            # ãƒˆãƒƒãƒ—10ã®ã¿å–å¾—
            if len(rankings) >= 10:
                break

        except (IndexError, AttributeError) as exc:
            logger.warning("è¡Œã®è§£æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: %s", exc)
            continue

    if not rankings:
        raise ValueError("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    logger.info("ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ %d ä»¶å–å¾—ã—ã¾ã—ãŸ", len(rankings))
    return rankings


# ===========================
# ãƒ‡ãƒ¼ã‚¿ä¿å­˜
# ===========================


def save_to_json(data: Dict[str, Any], slot: str) -> Path:
    """
    ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜ã™ã‚‹ã€‚

    Args:
        data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆè¾æ›¸å½¢å¼ï¼‰
        slot: ã‚¿ã‚¤ãƒ ã‚¹ãƒ­ãƒƒãƒˆè­˜åˆ¥å­ï¼ˆ"midday" or "close"ï¼‰

    Returns:
        Path: ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    DATA_ROOT.mkdir(parents=True, exist_ok=True)

    datetime_str = data["datetime"]
    filename = f"sector_{datetime_str}.json"
    filepath = DATA_ROOT / filename

    with filepath.open("w", encoding="utf-8") as file:
        json.dump(data, file, ensure_ascii=False, indent=2)

    logger.info("ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: %s", filepath)
    return filepath


# ===========================
# LINEé€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
# ===========================


def format_success_message(
    datetime_str: str,
    slot: str,
    rankings: List[Dict[str, str]],
) -> str:
    """
    ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—æˆåŠŸæ™‚ã®LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆã™ã‚‹ã€‚

    Args:
        datetime_str: å®Ÿè¡Œæ—¥æ™‚æ–‡å­—åˆ—
        slot: ã‚¿ã‚¤ãƒ ã‚¹ãƒ­ãƒƒãƒˆè­˜åˆ¥å­
        rankings: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿

    Returns:
        str: LINEé€šçŸ¥ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    slot_names = {
        "midday": "å‰å ´çµ‚äº†æ™‚",
        "close": "å¤§å¼•ã‘å¾Œ",
    }
    slot_name = slot_names.get(slot, slot)

    dt = datetime.datetime.strptime(datetime_str, DATETIME_FORMAT)
    formatted_time = dt.strftime("%Y-%m-%d %H:%M")

    lines = [
        f"ğŸ“Š {formatted_time}",
        f"æ¥­ç¨®åˆ¥é¨°è½ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ{slot_name}ï¼‰",
        "",
    ]

    for item in rankings[:10]:
        rank = item.get("rank", "?")
        sector = item.get("sector", "ä¸æ˜")
        change_pct = item.get("change_percent", "N/A")

        # è‰²ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
        if "+" in change_pct:
            color = "ğŸŸ¢"
        elif "-" in change_pct:
            color = "ğŸ”´"
        else:
            color = "âšª"

        lines.append(f"{rank}ä½: {sector} {color}{change_pct}")

    return "\n".join(lines)


def format_error_message(
    datetime_str: str,
    slot: str,
    error_msg: str,
) -> str:
    """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆã™ã‚‹ã€‚"""
    dt = datetime.datetime.strptime(datetime_str, DATETIME_FORMAT)
    formatted_time = dt.strftime("%Y-%m-%d %H:%M")

    return f"""âš ï¸ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼

æ™‚åˆ»: {formatted_time}
ã‚¹ãƒ­ãƒƒãƒˆ: {slot}
ã‚¨ãƒ©ãƒ¼: {error_msg}

ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"""


# ===========================
# æ™‚åˆ»åˆ¤å®š
# ===========================


def get_current_time_slot() -> Optional[Tuple[str, str]]:
    """
    ç¾åœ¨æ™‚åˆ»ã‹ã‚‰è©²å½“ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—ã™ã‚‹ã€‚

    Returns:
        Optional[Tuple[str, str]]: (slotè­˜åˆ¥å­, æ™‚åˆ»æ–‡å­—åˆ—) ã¾ãŸã¯ None
    """
    now = datetime.datetime.now(JST)
    current_time = now.strftime("%H:%M")

    for slot_time, slot_id in SECTOR_TIME_SLOTS.items():
        logger.info(
            "ç¾åœ¨æ™‚åˆ» %s ã¯ %s ã®ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥å®Ÿè¡Œæ™‚é–“å¸¯ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ï¼ˆè¨±å®¹å¹…åˆ¶é™ãªã—ï¼‰",
            current_time,
            slot_time,
        )
        return (slot_id, slot_time)

    return None


# ===========================
# é‡è¤‡å®Ÿè¡Œãƒã‚§ãƒƒã‚¯
# ===========================


def check_recent_execution(
    slot: str,
    slot_time: str,
    threshold_minutes: int = 10,
) -> bool:
    """
    æŒ‡å®šã‚¹ãƒ­ãƒƒãƒˆã®å®Ÿè¡Œæœ‰ç„¡ã‚’åˆ¤å®šã—ã¦é‡è¤‡å–å¾—ã‚’é¿ã‘ã‚‹ã€‚

    Args:
        slot: ã‚¿ã‚¤ãƒ ã‚¹ãƒ­ãƒƒãƒˆè­˜åˆ¥å­
        slot_time: äºˆå®šã‚¹ãƒ­ãƒƒãƒˆæ™‚åˆ»ï¼ˆä¾‹: "11:45"ï¼‰
        threshold_minutes: æ™‚åˆ»ãƒ™ãƒ¼ã‚¹åˆ¤å®šã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¾å€¤ï¼ˆåˆ†ï¼‰

    Returns:
        bool: True=é‡è¤‡ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—, False=å®Ÿè¡Œã™ã¹ã
    """
    if not DATA_ROOT.exists():
        return False

    json_files = sorted(
        DATA_ROOT.glob("sector_*.json"),
        key=lambda p: p.stat().st_mtime,
        reverse=True
    )

    if not json_files:
        return False

    now = datetime.datetime.now(JST)
    today = now.date()

    for candidate in json_files:
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºï¼ˆsector_YYYYMMDD_HHMM.jsonï¼‰
        try:
            name_parts = candidate.stem.split("_")
            if len(name_parts) >= 2:
                file_date_str = name_parts[1]  # YYYYMMDD
                file_date = datetime.datetime.strptime(file_date_str, "%Y%m%d").date()
            else:
                continue
        except (ValueError, IndexError):
            continue

        if file_date != today:
            continue

        try:
            with candidate.open("r", encoding="utf-8") as file:
                data = json.load(file)
        except (json.JSONDecodeError, OSError):
            continue

        if data.get("slot_time") == slot_time:
            logger.info(
                "ã‚¹ãƒ­ãƒƒãƒˆ %s ã¯æ—¢ã« %s ã«ä¿å­˜æ¸ˆã¿ã®ãŸã‚é‡è¤‡å®Ÿè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚",
                slot_time,
                candidate.name,
            )
            return True

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´è¿‘10åˆ†ä»¥å†…ã®ãƒã‚§ãƒƒã‚¯
    latest_file = json_files[0]
    file_mtime = datetime.datetime.fromtimestamp(latest_file.stat().st_mtime, tz=JST)
    diff_minutes = (now - file_mtime).total_seconds() / 60

    if diff_minutes < threshold_minutes:
        logger.info(
            "%.1fåˆ†å‰ã«å®Ÿè¡Œæ¸ˆã¿ã§ã™ï¼ˆ%sï¼‰ã€‚é‡è¤‡å®Ÿè¡Œã‚’é˜²æ­¢ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚",
            diff_minutes,
            latest_file.name,
        )
        return True

    return False


# ===========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===========================


def main() -> None:
    """ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ã‹ã‚‰LINEé€šçŸ¥ã¾ã§ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""

    separator = "=" * 60
    logger.info(separator)
    logger.info("SBIè¨¼åˆ¸ æ¥­ç¨®åˆ¥é¨°è½ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾— é–‹å§‹")

    today = datetime.datetime.now(JST).date()
    if CHECK_WORKDAY_FALLBACK:
        logger.warning("check_workday.py ãŒæœªå®Ÿè£…ã®ãŸã‚ç°¡æ˜“å–¶æ¥­æ—¥åˆ¤å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    if not is_trading_day(today):
        logger.info("%s ã¯å–å¼•æ—¥ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚", today)
        logger.info(separator)
        return

    slot_info = get_current_time_slot()

    if slot_info is None:
        current_time = datetime.datetime.now(JST).strftime("%H:%M")
        logger.info(
            "ç¾åœ¨æ™‚åˆ» %s ã¯ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥å–å¾—å¯¾è±¡ã®æ™‚é–“å¸¯ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚",
            current_time,
        )
        logger.info(separator)
        return

    slot, slot_time_str = slot_info

    # é‡è¤‡å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ï¼ˆ10åˆ†ä»¥å†…ã«å®Ÿè¡Œæ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    if check_recent_execution(slot, slot_time_str, threshold_minutes=10):
        logger.info("é‡è¤‡å®Ÿè¡Œã‚’é˜²æ­¢ã™ã‚‹ãŸã‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        logger.info(separator)
        return

    try:
        rankings = scrape_sector_ranking(SECTOR_URL)
    except Exception as exc:
        datetime_str = datetime.datetime.now(JST).strftime(DATETIME_FORMAT)
        error_message = format_error_message(datetime_str, slot, str(exc))
        success = send_line_notify(error_message)
        if not success:
            logger.error("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆã‚¨ãƒ©ãƒ¼é€šçŸ¥ï¼‰")
            raise RuntimeError("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ") from exc
        logger.error("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", exc)
        logger.info(separator)
        raise

    now = datetime.datetime.now(JST)
    datetime_str = now.strftime(DATETIME_FORMAT)
    data: Dict[str, Any] = {
        "datetime": datetime_str,
        "slot_time": slot_time_str,
        "slot": slot,
        "url": SECTOR_URL,
        "scraped_at": now.isoformat(),
        "rankings": rankings,
    }

    filepath = save_to_json(data, slot)

    message = format_success_message(datetime_str, slot, rankings)
    success = send_line_notify(message)
    if not success:
        logger.error("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆæˆåŠŸé€šçŸ¥ï¼‰")
        raise RuntimeError("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")

    if not LINE_NOTIFY_AVAILABLE:
        logger.info("LINEé€šçŸ¥ã¯ãƒ­ã‚°å‡ºåŠ›ã®ã¿ (notify_line.py æœªå®Ÿè£…)ã€‚")

    logger.info("JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: %s", filepath)
    logger.info("SBIè¨¼åˆ¸ æ¥­ç¨®åˆ¥é¨°è½ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾— å®Œäº†")
    logger.info(separator)


if __name__ == "__main__":
    main()
