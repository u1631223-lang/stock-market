"""
ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚° ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ ªæ¢ï¼ˆkabutan.jpï¼‰ã®ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ã—ã€
ä¸Šæ˜‡TOP5ã¨ä¸‹è½TOP5ã‚’LINEé€šçŸ¥ã™ã‚‹ã€‚
"""

import datetime
import json
import logging
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
from zoneinfo import ZoneInfo

import requests
from bs4 import BeautifulSoup

# åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import (
    SECTOR_RANKING_URL,
    SECTOR_TIME_SLOTS,
    SECTOR_DATA_DIR,
    USER_AGENT,
    REQUEST_TIMEOUT,
    RETRY_COUNT,
    RETRY_DELAYS,
)
from check_workday import is_trading_day

# JST ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = ZoneInfo("Asia/Tokyo")

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)

# æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
DATETIME_FORMAT = "%Y%m%d_%H%M"


def get_current_time_slot() -> Optional[str]:
    """
    ç¾åœ¨æ™‚åˆ»ãŒå±ã™ã‚‹å–å¾—å¯¾è±¡ã‚’åˆ¤å®šã™ã‚‹ã€‚

    GitHub Actions ã® cron å®Ÿè¡Œã«ã¯é…å»¶ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€
    è¨­å®šæ™‚åˆ»ã®Â±15åˆ†ä»¥å†…ã§ã‚ã‚Œã°è©²å½“ã™ã‚‹æ™‚é–“å¸¯ã¨ã—ã¦åˆ¤å®šã™ã‚‹ã€‚

    Returns:
        str: å–å¾—å¯¾è±¡ ("midday" or "closing")ã€è©²å½“ãªã—ã®å ´åˆã¯ None
    """
    now = datetime.datetime.now(JST)

    best_match = None
    min_diff = float('inf')

    # å„SECTOR_TIME_SLOTã«å¯¾ã—ã¦ã€æœ€ã‚‚è¿‘ã„æ™‚åˆ»ã‚’æ¢ã™
    for time_str, target in SECTOR_TIME_SLOTS.items():
        slot_hour, slot_minute = map(int, time_str.split(":"))
        slot_time = now.replace(hour=slot_hour, minute=slot_minute, second=0, microsecond=0)

        # ç¾åœ¨æ™‚åˆ»ã¨ã®å·®åˆ†ã‚’è¨ˆç®—
        time_diff = abs((now - slot_time).total_seconds())

        # Â±15åˆ†ï¼ˆ900ç§’ï¼‰ä»¥å†…ã§ã€ã‹ã¤æœ€ã‚‚è¿‘ã„æ™‚åˆ»ã‚’é¸æŠ
        if time_diff <= 900 and time_diff < min_diff:
            min_diff = time_diff
            best_match = (time_str, target)

    if best_match:
        time_str, target = best_match
        logger.info(f"ç¾åœ¨æ™‚åˆ» {now.strftime('%H:%M')} ã¯ {time_str} ã®å®Ÿè¡Œæ™‚é–“å¸¯ã§ã™ï¼ˆè¨±å®¹ç¯„å›²: Â±15åˆ†ï¼‰")
        return target

    return None


def scrape_sector_ranking(url: str) -> List[Dict[str, str]]:
    """
    ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã€‚

    Args:
        url: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡URL

    Returns:
        List[Dict]: ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            å„è¦ç´ ã¯ {"code": "0263", "name": "éé‰„é‡‘å±", "change_percent": "+3.06"}

    Raises:
        Exception: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—æ™‚
    """
    headers = {"User-Agent": USER_AGENT}

    # ãƒªãƒˆãƒ©ã‚¤å‡¦ç†
    for attempt in range(1, RETRY_COUNT + 1):
        try:
            logger.info(f"HTTP GET: {url} (è©¦è¡Œ {attempt}/{RETRY_COUNT})")
            response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            logger.info(f"HTTP GET æˆåŠŸ: status={response.status_code}")
            break
        except requests.exceptions.RequestException as e:
            if attempt == RETRY_COUNT:
                logger.error(f"HTTP GET å¤±æ•— (è©¦è¡Œ {attempt}/{RETRY_COUNT}): {e}")
                raise
            else:
                delay_index = min(attempt - 1, len(RETRY_DELAYS) - 1)
                delay = RETRY_DELAYS[delay_index]
                logger.warning(f"HTTP GET å¤±æ•— (è©¦è¡Œ {attempt}/{RETRY_COUNT}): {e}")
                logger.info(f"{delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                time.sleep(delay)

    # HTMLè§£æ
    soup = BeautifulSoup(response.content, "lxml")

    # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
    table = soup.find("table", class_="stock_kabuka_dwm")
    if not table:
        table = soup.find("table", class_="stock_table")
    if not table:
        table = soup.find("table")

    if not table:
        raise ValueError("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # tbodyå†…ã®å„è¡Œã‚’è§£æ
    tbody = table.find("tbody")
    if not tbody:
        raise ValueError("ãƒ†ãƒ¼ãƒ–ãƒ«ã®tbodyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    sectors = []
    rows = tbody.find_all("tr")

    for row in rows:
        try:
            cells = row.find_all(["td", "th"])
            if len(cells) < 7:  # æœ€ä½é™ã®åˆ—æ•°ãƒã‚§ãƒƒã‚¯
                continue

            # ã‚³ãƒ¼ãƒ‰: æœ€åˆã®tdå†…ã®aã‚¿ã‚°ã®ãƒ†ã‚­ã‚¹ãƒˆ
            code_cell = cells[0]
            code_link = code_cell.find("a")
            code = code_link.text.strip() if code_link else ""

            # ã‚»ã‚¯ã‚¿ãƒ¼å: 2ç•ªç›®ã®thå†…ã®aã‚¿ã‚°ã®ãƒ†ã‚­ã‚¹ãƒˆ
            name_cell = cells[1]
            name_link = name_cell.find("a")
            name = name_link.text.strip() if name_link else ""

            # å‰æ—¥æ¯”ï¼ˆ%ï¼‰: 7ç•ªç›®ã®tdå†…ã®spanã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ%è¨˜å·ã‚’é™¤ãï¼‰
            change_percent_cell = cells[6]
            change_span = change_percent_cell.find("span")
            if change_span:
                change_text = change_span.text.strip()
                # %è¨˜å·ã‚’é™¤å»
                change_percent = change_text.replace("%", "").strip()
            else:
                change_percent = "0.00"

            if code and name and change_percent:
                sectors.append({
                    "code": code,
                    "name": name,
                    "change_percent": change_percent
                })

        except (IndexError, AttributeError) as e:
            logger.warning(f"è¡Œã®ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {e}")
            continue

    if not sectors:
        raise ValueError("ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    logger.info(f"ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—: {len(sectors)}ä»¶")
    return sectors


def save_to_json(data: Dict[str, Any], target: str) -> str:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜ã™ã‚‹ã€‚

    Args:
        data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
        target: å–å¾—å¯¾è±¡ ("midday" or "closing")

    Returns:
        str: ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    sector_dir = Path(__file__).parent.parent / SECTOR_DATA_DIR
    sector_dir.mkdir(parents=True, exist_ok=True)

    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
    datetime_str = data["datetime"]
    filename = f"ranking_{datetime_str}.json"
    filepath = sector_dir / filename

    # JSONä¿å­˜
    logger.info(f"JSONä¿å­˜: {filepath}")
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    logger.info(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
    return str(filepath)


def format_sector_message(datetime_str: str, target: str, top5: List[Dict], bottom5: List[Dict]) -> str:
    """
    ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®LINEé€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹ã€‚

    Args:
        datetime_str: æ—¥æ™‚æ–‡å­—åˆ—ï¼ˆä¾‹: "2025-10-27 12:00"ï¼‰
        target: "midday" or "closing"
        top5: ä¸Šæ˜‡TOP5ã®ãƒªã‚¹ãƒˆ
        bottom5: ä¸‹è½TOP5ã®ãƒªã‚¹ãƒˆ

    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    # æ—¥æœ¬èªã®æ™‚é–“å¸¯å
    target_name = "æ˜¼ä¼‘ã¿" if target == "midday" else "å¤§å¼•ã‘å¾Œ"

    # åŸºæœ¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    message = f"ğŸ“Š {datetime_str}\n"
    message += f"ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚° ({target_name})\n"

    # ä¸Šæ˜‡TOP5
    message += "\nã€ä¸Šæ˜‡TOP5ã€‘ğŸŸ¢\n"
    for i, sector in enumerate(top5, 1):
        name = sector["name"]
        change = sector["change_percent"]
        # ç¬¦å·ã‚’æ˜ç¤ºçš„ã«è¿½åŠ ï¼ˆãƒ—ãƒ©ã‚¹ã®å ´åˆï¼‰
        if not change.startswith(("+", "-")):
            change = f"+{change}"
        message += f"{i}ä½: {name} {change}%\n"

    # ä¸‹è½TOP5
    message += "\nã€ä¸‹è½TOP5ã€‘ğŸ”´\n"
    for i, sector in enumerate(bottom5, 1):
        name = sector["name"]
        change = sector["change_percent"]
        # ç¬¦å·ã‚’æ˜ç¤ºçš„ã«è¿½åŠ ï¼ˆãƒã‚¤ãƒŠã‚¹ã®å ´åˆï¼‰
        if not change.startswith(("+", "-")):
            change = f"-{change}"
        message += f"{i}ä½: {name} {change}%\n"

    # ã‚µãƒãƒªãƒ¼
    if top5:
        top_names = ", ".join([s["name"] for s in top5[:2]])
        message += f"\nğŸ’¡ è³‡é‡‘æµå…¥: {top_names}"
    if bottom5:
        bottom_names = ", ".join([s["name"] for s in bottom5[:2]])
        message += f"\nğŸ’¡ è³‡é‡‘æµå‡º: {bottom_names}"

    return message


def send_sector_line_notify(message: str) -> bool:
    """
    ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®LINEé€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹ã€‚

    Args:
        message: é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        bool: é€ä¿¡æˆåŠŸæ™‚ Trueã€å¤±æ•—æ™‚ False
    """
    # notify_line.pyã®send_line_notifyã‚’ä½¿ç”¨
    from notify_line import send_line_notify
    return send_line_notify(message)


def format_error_message(datetime_str: str, target: str, error: str) -> str:
    """
    ã‚¨ãƒ©ãƒ¼æ™‚ã®LINEé€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒˆã™ã‚‹ã€‚

    Args:
        datetime_str: æ—¥æ™‚æ–‡å­—åˆ—
        target: "midday" or "closing"
        error: ã‚¨ãƒ©ãƒ¼å†…å®¹

    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    target_name = "æ˜¼ä¼‘ã¿" if target == "midday" else "å¤§å¼•ã‘å¾Œ"

    message = f"âŒ [ã‚¨ãƒ©ãƒ¼] {datetime_str}\n"
    message += f"ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—å¤±æ•— ({target_name})\n"
    message += f"\nã‚¨ãƒ©ãƒ¼å†…å®¹:\n{error}"

    return message


def main() -> None:
    """ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ã‹ã‚‰LINEé€šçŸ¥ã¾ã§ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""

    separator = "=" * 60
    logger.info(separator)
    logger.info("ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾— é–‹å§‹")

    today = datetime.datetime.now(JST).date()

    if not is_trading_day(today):
        logger.info("%s ã¯å–å¼•æ—¥ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚", today)
        logger.info(separator)
        return

    target = get_current_time_slot()
    if target is None:
        current_time = datetime.datetime.now(JST).strftime("%H:%M")
        logger.info(
            "ç¾åœ¨æ™‚åˆ» %s ã¯å–å¾—å¯¾è±¡ã®æ™‚é–“å¸¯ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚",
            current_time,
        )
        logger.info(separator)
        return

    url = SECTOR_RANKING_URL

    try:
        sectors = scrape_sector_ranking(url)
    except Exception as exc:
        now = datetime.datetime.now(JST)
        datetime_str = now.strftime("%Y-%m-%d %H:%M")
        error_message = format_error_message(datetime_str, target, str(exc))
        success = send_sector_line_notify(error_message)
        if not success:
            logger.error("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆã‚¨ãƒ©ãƒ¼é€šçŸ¥ï¼‰")
            raise RuntimeError("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ") from exc
        logger.error("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", exc)
        logger.info(separator)
        raise

    # å‰æ—¥æ¯”ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆä¸Šæ˜‡é †ï¼‰
    sectors_sorted_desc = sorted(sectors, key=lambda x: float(x["change_percent"]), reverse=True)
    top5 = sectors_sorted_desc[:5]

    # å‰æ—¥æ¯”ã§æ˜‡é †ã‚½ãƒ¼ãƒˆï¼ˆä¸‹è½é †ï¼‰
    sectors_sorted_asc = sorted(sectors, key=lambda x: float(x["change_percent"]))
    bottom5 = sectors_sorted_asc[:5]

    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    now = datetime.datetime.now(JST)
    datetime_str_file = now.strftime(DATETIME_FORMAT)
    datetime_str_display = now.strftime("%Y-%m-%d %H:%M")

    data: Dict[str, Any] = {
        "datetime": datetime_str_file,
        "url": url,
        "scraped_at": now.isoformat(),
        "sectors": sectors,
        "top5": top5,
        "bottom5": bottom5
    }

    filepath = save_to_json(data, target)

    # LINEé€šçŸ¥
    message = format_sector_message(datetime_str_display, target, top5, bottom5)
    success = send_sector_line_notify(message)
    if not success:
        logger.error("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆæˆåŠŸé€šçŸ¥ï¼‰")
        raise RuntimeError("LINEé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")

    logger.info("JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: %s", filepath)
    logger.info("ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾— å®Œäº†")
    logger.info(separator)


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        sys.exit(1)
