# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is an automated stock ranking scraper that collects rankings from Matsui Securities (æ¾äº•è¨¼åˆ¸) and Kabutan (æ ªæ¢) at specific times during trading days. It runs on GitHub Actions and sends notifications via LINE Messaging API.

**Note:** LINE Notify was discontinued on March 31, 2025. This project has been migrated to LINE Messaging API.

**Target URLs:**

1. **æ¾äº•è¨¼åˆ¸ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆè³‡é‡‘æµå…¥ï¼‰:**
   - Morning: `https://finance.matsui.co.jp/ranking-day-trading-morning/index?condition=0&market=0`
   - Afternoon: `https://finance.matsui.co.jp/ranking-day-trading-afternoon/index?condition=0&market=0`

2. **æ ªæ¢ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**
   - URL: `https://kabutan.jp/warning/?mode=9_1`

**Execution Schedule (JST, Â±15åˆ†ã®è¨±å®¹ç¯„å›²ã‚ã‚Š):**
- 09:20 - æ¾äº•è¨¼åˆ¸ åˆå‰ä¸­è³‡é‡‘æµå…¥
- 09:35 - æ¾äº•è¨¼åˆ¸ åˆå‰ä¸­è³‡é‡‘æµå…¥
- **12:00** - **æ ªæ¢ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ï¼ˆæ˜¼ä¼‘ã¿ï¼‰** â† æ–°è¦
- 12:02 - æ¾äº•è¨¼åˆ¸ åˆå‰ä¸­è³‡é‡‘æµå…¥
- 12:47 - æ¾äº•è¨¼åˆ¸ åˆå¾Œè³‡é‡‘æµå…¥
- 14:32 - æ¾äº•è¨¼åˆ¸ åˆå¾Œè³‡é‡‘æµå…¥
- **16:00** - **æ ªæ¢ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ï¼ˆå¤§å¼•ã‘å¾Œï¼‰** â† æ–°è¦
- Only runs on weekdays (excluding Japanese holidays)
- **æ³¨æ„**: GitHub Actions cronã¯UTC 00:00-00:30å°ãŒå®Ÿè¡Œã•ã‚Œãªã„ãŸã‚ã€09:20,09:35ã«å¤‰æ›´ã—ã¦ã„ã¾ã™

## Architecture

**Execution Flow:**

**æ¾äº•è¨¼åˆ¸ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**
1. `check_workday.py` - Validates trading day (weekend/holiday check using jpholiday)
2. `scrape_rankings.py` - Main orchestrator: determines time slot, scrapes data, loads previous ranking, saves JSON
3. `notify_line.py` - Sends success/failure notifications to LINE with ranking changes
4. GitHub Actions commits results to `data/morning/` or `data/afternoon/`

**æ ªæ¢ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**
1. `check_workday.py` - Validates trading day (weekend/holiday check using jpholiday)
2. `scrape_sector_ranking.py` - Scrapes sector rankings, calculates top5/bottom5, saves JSON
3. `notify_line.py` - Sends notifications with color-coded sector rankings (ğŸŸ¢ up, ğŸ”´ down)
4. GitHub Actions commits results to `data/sector/`

**Module Responsibilities:**
- `config.py` - Central configuration (URLs, time slots, retry logic, User-Agent)
- `check_workday.py` - Trading day validation (åœŸæ—¥ç¥åˆ¤å®š)
- `scrape_rankings.py` - Matsui Securities ranking scraper (HTTP requests, HTML parsing, JSON storage)
- `scrape_sector_ranking.py` - Kabutan sector ranking scraper (HTTP requests, HTML parsing, top5/bottom5 calculation)
- `notify_line.py` - LINE Messaging API integration with message formatting and ranking change display

**Data Flow:**
```
GitHub Actions Cron â†’ check_workday â†’ scrape_rankings â†’ load previous ranking
â†’ BeautifulSoup parsing â†’ JSON save to data/{morning|afternoon}/
â†’ git commit/push â†’ LINE notification with ranking changes
```

## Development Commands

### Local Testing

```bash
# Setup virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Test individual modules
cd src
python check_workday.py              # Test trading day logic

# Test LINE Messaging API notification
export LINE_CHANNEL_ACCESS_TOKEN="your_channel_access_token"
export LINE_TARGET_USER_ID="your_user_id"
python notify_line.py                # Test LINE notification

python scrape_rankings.py            # Test full scraping flow
```

### Testing Scraping Outside Scheduled Times

To test scraping when it's not one of the scheduled times, temporarily modify `scrape_rankings.py`:

```python
# In main() function, replace:
target = get_current_time_slot()
# With:
target = "morning"  # or "afternoon"
```

**Important:** Revert this change before committing.

### GitHub Actions

```bash
# Trigger manual workflow run
# Go to: Actions â†’ Scheduled Ranking Scrape â†’ Run workflow

# View logs
# Actions tab â†’ Select workflow run â†’ View step logs
```

## Critical Implementation Details

### HTML Structure Dependency

The `scrape_ranking()` function in `scrape_rankings.py` contains HTML parsing logic that **must be adjusted** based on actual page structure:

```python
# Multiple fallback patterns for finding the ranking table
table = soup.find("table", class_="ranking-table")  # Pattern 1
if not table:
    table = soup.find("table", id="rankingTable")   # Pattern 2
if not table:
    table = soup.find("table")                       # Pattern 3
```

**When HTML structure changes:**
1. Open target URL in browser
2. Use DevTools (F12) to inspect table structure
3. Update selectors in `scrape_ranking()` to match actual class names, IDs, and column indices
4. Test locally before pushing

### Anti-Scraping Measures

The site returns 403 errors without proper User-Agent. Current implementation:
- Sets browser-like User-Agent in `config.py`
- Implements retry logic (3 attempts with exponential backoff: 5s, 10s, 20s)
- Respects rate limits (only 1 request per scheduled time)

### Time Zone Handling

- GitHub Actions cron runs in UTC
- All cron times in workflow are UTC equivalents of JST times
- Python code uses `ZoneInfo("Asia/Tokyo")` for JST
- Current time comparison uses JST for matching TIME_SLOTS

### Error Handling Strategy

All exceptions in `scrape_rankings.py` trigger LINE notifications with error details. Common failures:
- `requests.exceptions.RequestException` â†’ Network/HTTP errors â†’ Retried
- `AttributeError` â†’ HTML structure changed â†’ Immediate notification
- Weekend/holiday execution â†’ Silent skip (no notification)

## Configuration

### Environment Variables

**Required for LINE Messaging API (since March 31, 2025):**
- `LINE_CHANNEL_ACCESS_TOKEN` - Channel access token from LINE Developers
- `LINE_TARGET_USER_ID` - User ID to send notifications to

Set these in GitHub Secrets (Settings â†’ Secrets and variables â†’ Actions)

### Key Config Values (src/config.py)

- `URLS` - Target scraping URLs
- `TIME_SLOTS` - Valid execution times (HH:MM format in JST)
- `RETRY_COUNT` / `RETRY_DELAYS` - Retry behavior
- `USER_AGENT` - Browser identification string
- `DATA_DIR` - Output directory for JSON files

## Data Format

JSON files saved as `data/{morning|afternoon}/ranking_YYYYMMDD_HHMM.json`:

```json
{
  "datetime": "20251020_0915",
  "url": "https://...",
  "scraped_at": "2025-10-20T09:15:03+09:00",
  "rankings": [
    {
      "rank": "1",
      "code": "1234",
      "name": "Company Name",
      "price": "1,234",
      "change": "+56",
      "change_percent": "+4.76%",
      "volume": "12,345,678",
      "value": "1,234,567,890"
    }
  ]
}
```

**Note:** Actual fields depend on HTML structure and may need adjustment.

## Documentation

Comprehensive documentation in `docs/`:
- `requirements.md` - Full requirements and constraints
- `architecture.md` - System design, component responsibilities, operational procedures
- `technical-stack.md` - Technology choices and rationale
- `implementation-guide.md` - Complete code implementations with troubleshooting
- `setup-guide.md` - Step-by-step setup from scratch

## LINE Notification Format

### æ¾äº•è¨¼åˆ¸ãƒ©ãƒ³ã‚­ãƒ³ã‚°

**Format (2025-10-24 updated with color indicators):**
```
ğŸ“Š 2025-10-24 09:32
åˆå‰ä¸­è³‡é‡‘æµå…¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°

1ä½: [285A] ã‚­ã‚ªã‚¯ã‚·ã‚¢ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ ğŸŸ¢+11.94% ğŸ”ºâ†‘1
2ä½: [9984] ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ— ğŸŸ¢+3.37% ğŸ”»â†“1
3ä½: [6920] ãƒ¬ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒƒã‚¯ ğŸŸ¢+3.90% -
4ä½: [6857] ã‚¢ãƒ‰ãƒãƒ³ãƒ†ã‚¹ãƒˆ ğŸŸ¢+3.23% ğŸ”ºâ†‘1
5ä½: [3692] ï¼¦ï¼¦ï¼²ï¼©ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ ğŸŸ¢+12.73% ğŸ†•NEW
...
```

**Color indicators:**
- ğŸŸ¢ **Green**: Stock price increase (+)
- ğŸ”´ **Red**: Stock price decrease (-)

### ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°

**Format (2025-10-24 new):**
```
ğŸ“Š 2025-10-27 12:00
ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚° (æ˜¼ä¼‘ã¿)

ã€ä¸Šæ˜‡TOP5ã€‘ğŸŸ¢
1ä½: éé‰„é‡‘å± +3.06%
2ä½: é›»æ°—æ©Ÿå™¨ +2.85%
3ä½: è¼¸é€ç”¨æ©Ÿå™¨ +2.31%
4ä½: æ©Ÿæ¢° +1.98%
5ä½: åŒ–å­¦ +1.76%

ã€ä¸‹è½TOP5ã€‘ğŸ”´
1ä½: éŠ€è¡Œæ¥­ -2.34%
2ä½: ä¿é™ºæ¥­ -1.98%
3ä½: ãã®ä»–é‡‘èæ¥­ -1.67%
4ä½: æµ·é‹æ¥­ -1.45%
5ä½: é‰±æ¥­ -1.23%

ğŸ’¡ è³‡é‡‘æµå…¥: éé‰„é‡‘å±ã€é›»æ°—æ©Ÿå™¨
ğŸ’¡ è³‡é‡‘æµå‡º: éŠ€è¡Œæ¥­ã€ä¿é™ºæ¥­
```

**Color indicators:**
- ğŸŸ¢ **Green**: Sector increase (top 5 gainers)
- ğŸ”´ **Red**: Sector decrease (top 5 losers)

## Ranking Change Indicators

**For Matsui Securities rankings:**
- ğŸ”ºâ†‘N: Rank improved (moved up N positions)
- ğŸ”»â†“N: Rank declined (moved down N positions)
- -: No change from previous ranking
- ğŸ†•NEW: New entry (not in previous top 10)

**Note:** First execution of the day (09:20) shows no ranking changes as there's no previous data to compare.

## System Status

**âœ… Production Ready (2025-10-24)**

All components have been tested and verified:
- âœ… GitHub Actions automatic execution configured (cron adjusted to avoid congestion)
- âœ… æ¾äº•è¨¼åˆ¸ãƒ©ãƒ³ã‚­ãƒ³ã‚° scraping functionality working correctly (top 10 rankings)
- âœ… æ ªæ¢ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é¨°è½ãƒ©ãƒ³ã‚­ãƒ³ã‚° scraping functionality implemented
- âœ… LINE Messaging API notifications verified with ranking changes and color indicators
- âœ… Git auto-commit with proper permissions
- âœ… Error handling and retry logic tested
- âœ… Ranking change detection implemented

**Next scheduled execution:** Weekdays at 09:20, 09:35, 12:00, 12:02, 12:47, 14:32, 16:00 JST (Â±15åˆ†)

## Common Issues

**"ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" error:**
- HTML structure has changed
- Inspect actual page structure and update `scrape_ranking()` table selectors

**LINE notification not working:**
- Verify `LINE_CHANNEL_ACCESS_TOKEN` and `LINE_TARGET_USER_ID` are set in GitHub Secrets
- User ID must be in format `Uxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` (33 characters starting with U)
- Test token validity locally with `notify_line.py`

**Execution on holidays:**
- Verify jpholiday is correctly installed
- Check `check_workday.py` logic for date in question

**403 Forbidden errors:**
- æ¾äº•è¨¼åˆ¸ may have strengthened anti-scraping measures
- May need to adjust User-Agent or implement additional headers
- Consider adding referrer headers or cookies if needed

**GitHub Actions permission errors:**
- Settings â†’ Actions â†’ General â†’ Workflow permissions
- Set to "Read and write permissions"
